{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "\n",
      "=== Evaluating esm1b_t33_650M_UR50S ===\n",
      "\n",
      "[esm1b_t33_650M_UR50S] Loading model...\n",
      "Model loaded âœ“  (652.4 M params)\n",
      "ðŸ”¹ Found cached file: ESM1b_650M.csv\n",
      "\n",
      "ðŸ”¹ SVM (RBF) (5-fold CV)\n",
      "  Fold 1: acc=0.9126, auc=0.9496\n",
      "  Fold 2: acc=0.9612, auc=0.9636\n",
      "  Fold 3: acc=0.9903, auc=0.9977\n",
      "  Fold 4: acc=0.9612, auc=0.9807\n",
      "  Fold 5: acc=0.9118, auc=0.9838\n",
      "\n",
      "ðŸ”¹ Logistic Regression (5-fold CV)\n",
      "  Fold 1: acc=0.9223, auc=0.9523\n",
      "  Fold 2: acc=0.9612, auc=0.9643\n",
      "  Fold 3: acc=0.9709, auc=0.9775\n",
      "  Fold 4: acc=0.9515, auc=0.9773\n",
      "  Fold 5: acc=0.9706, auc=0.9673\n",
      "\n",
      "ðŸ”¹ Random Forest (5-fold CV)\n",
      "  Fold 1: acc=0.9126, auc=0.9626\n",
      "  Fold 2: acc=0.9612, auc=0.9715\n",
      "  Fold 3: acc=0.9515, auc=0.9934\n",
      "  Fold 4: acc=0.9126, auc=0.9744\n",
      "  Fold 5: acc=0.9020, auc=0.9732\n",
      "\n",
      "ðŸ”¹ XGBoost (5-fold CV)\n",
      "  Fold 1: acc=0.9029, auc=0.9605\n",
      "  Fold 2: acc=0.9515, auc=0.9647\n",
      "  Fold 3: acc=0.9515, auc=0.9922\n",
      "  Fold 4: acc=0.9515, auc=0.9753\n",
      "  Fold 5: acc=0.9118, auc=0.9622\n",
      "â±  esm1b_t33_650M_UR50S done in 0.2 min\n",
      "\n",
      "\n",
      "=== Evaluating esm2_t6_8M_UR50D ===\n",
      "\n",
      "[esm2_t6_8M_UR50D] Loading model...\n",
      "Model loaded âœ“  (7.5 M params)\n",
      "ðŸ”¹ Found cached file: ESM2_8M.csv\n",
      "\n",
      "ðŸ”¹ SVM (RBF) (5-fold CV)\n",
      "  Fold 1: acc=0.8252, auc=0.9058\n",
      "  Fold 2: acc=0.9126, auc=0.9593\n",
      "  Fold 3: acc=0.8835, auc=0.9671\n",
      "  Fold 4: acc=0.9126, auc=0.9676\n",
      "  Fold 5: acc=0.8333, auc=0.9318\n",
      "\n",
      "ðŸ”¹ Logistic Regression (5-fold CV)\n",
      "  Fold 1: acc=0.9029, auc=0.9267\n",
      "  Fold 2: acc=0.9417, auc=0.9543\n",
      "  Fold 3: acc=0.9612, auc=0.9942\n",
      "  Fold 4: acc=0.8932, auc=0.9434\n",
      "  Fold 5: acc=0.9020, auc=0.9291\n",
      "\n",
      "ðŸ”¹ Random Forest (5-fold CV)\n",
      "  Fold 1: acc=0.7573, auc=0.8477\n",
      "  Fold 2: acc=0.8350, auc=0.8926\n",
      "  Fold 3: acc=0.8155, auc=0.9326\n",
      "  Fold 4: acc=0.8350, auc=0.9299\n",
      "  Fold 5: acc=0.8235, auc=0.8563\n",
      "\n",
      "ðŸ”¹ XGBoost (5-fold CV)\n",
      "  Fold 1: acc=0.7961, auc=0.8748\n",
      "  Fold 2: acc=0.8544, auc=0.9217\n",
      "  Fold 3: acc=0.8350, auc=0.9484\n",
      "  Fold 4: acc=0.8641, auc=0.9068\n",
      "  Fold 5: acc=0.8137, auc=0.8739\n",
      "â±  esm2_t6_8M_UR50D done in 0.1 min\n",
      "\n",
      "\n",
      "=== Evaluating esm2_t33_650M_UR50D ===\n",
      "\n",
      "[esm2_t33_650M_UR50D] Loading model...\n",
      "Model loaded âœ“  (651.0 M params)\n",
      "ðŸ”¹ Found cached file: ESM2_650M.csv\n",
      "\n",
      "ðŸ”¹ SVM (RBF) (5-fold CV)\n",
      "  Fold 1: acc=0.9029, auc=0.9736\n",
      "  Fold 2: acc=0.9515, auc=0.9636\n",
      "  Fold 3: acc=0.9709, auc=0.9984\n",
      "  Fold 4: acc=0.9709, auc=0.9773\n",
      "  Fold 5: acc=0.9314, auc=0.9882\n",
      "\n",
      "ðŸ”¹ Logistic Regression (5-fold CV)\n",
      "  Fold 1: acc=0.9320, auc=0.9713\n",
      "  Fold 2: acc=0.9709, auc=0.9512\n",
      "  Fold 3: acc=0.9806, auc=0.9961\n",
      "  Fold 4: acc=0.9417, auc=0.9873\n",
      "  Fold 5: acc=0.9412, auc=0.9831\n",
      "\n",
      "ðŸ”¹ Random Forest (5-fold CV)\n",
      "  Fold 1: acc=0.9223, auc=0.9721\n",
      "  Fold 2: acc=0.9417, auc=0.9692\n",
      "  Fold 3: acc=0.9223, auc=0.9808\n",
      "  Fold 4: acc=0.9126, auc=0.9576\n",
      "  Fold 5: acc=0.9216, auc=0.9811\n",
      "\n",
      "ðŸ”¹ XGBoost (5-fold CV)\n",
      "  Fold 1: acc=0.8932, auc=0.9682\n",
      "  Fold 2: acc=0.9320, auc=0.9609\n",
      "  Fold 3: acc=0.9223, auc=0.9895\n",
      "  Fold 4: acc=0.9515, auc=0.9615\n",
      "  Fold 5: acc=0.9020, auc=0.9606\n",
      "â±  esm2_t33_650M_UR50D done in 0.2 min\n",
      "\n",
      "\n",
      "=== Evaluating esm2_t36_3B_UR50D ===\n",
      "\n",
      "[esm2_t36_3B_UR50D] Loading model...\n",
      "Model loaded âœ“  (2839.0 M params)\n",
      "ðŸ”¹ Found cached file: ESM2_3B.csv\n",
      "\n",
      "ðŸ”¹ SVM (RBF) (5-fold CV)\n",
      "  Fold 1: acc=0.9126, auc=0.9756\n",
      "  Fold 2: acc=0.9709, auc=0.9686\n",
      "  Fold 3: acc=0.9806, auc=0.9996\n",
      "  Fold 4: acc=0.9806, auc=0.9823\n",
      "  Fold 5: acc=0.9216, auc=0.9653\n",
      "\n",
      "ðŸ”¹ Logistic Regression (5-fold CV)\n",
      "  Fold 1: acc=0.9223, auc=0.9694\n",
      "  Fold 2: acc=0.9806, auc=0.9694\n",
      "  Fold 3: acc=0.9612, auc=0.9981\n",
      "  Fold 4: acc=0.9320, auc=0.9727\n",
      "  Fold 5: acc=0.9608, auc=0.9515\n",
      "\n",
      "ðŸ”¹ Random Forest (5-fold CV)\n",
      "  Fold 1: acc=0.9223, auc=0.9752\n",
      "  Fold 2: acc=0.9612, auc=0.9731\n",
      "  Fold 3: acc=0.9806, auc=0.9961\n",
      "  Fold 4: acc=0.9709, auc=0.9859\n",
      "  Fold 5: acc=0.9216, auc=0.9590\n",
      "\n",
      "ðŸ”¹ XGBoost (5-fold CV)\n",
      "  Fold 1: acc=0.9223, auc=0.9686\n",
      "  Fold 2: acc=0.9709, auc=0.9725\n",
      "  Fold 3: acc=0.9709, auc=0.9953\n",
      "  Fold 4: acc=0.9709, auc=0.9788\n",
      "  Fold 5: acc=0.9510, auc=0.9539\n",
      "â±  esm2_t36_3B_UR50D done in 0.4 min\n",
      "\n",
      "\n",
      "âœ… All results saved to ESM_Benchmark_5fold.xlsx\n",
      "\n",
      "ðŸ Final Summary\n",
      "                  Model           Classifier  Accuracy_mean  Accuracy_std  \\\n",
      "0  esm1b_t33_650M_UR50S            SVM (RBF)       0.947401      0.030653   \n",
      "1  esm1b_t33_650M_UR50S  Logistic Regression       0.955283      0.017958   \n",
      "2  esm1b_t33_650M_UR50S        Random Forest       0.927965      0.023669   \n",
      "3  esm1b_t33_650M_UR50S              XGBoost       0.933809      0.021794   \n",
      "0      esm2_t6_8M_UR50D            SVM (RBF)       0.873463      0.037691   \n",
      "1      esm2_t6_8M_UR50D  Logistic Regression       0.920198      0.026468   \n",
      "2      esm2_t6_8M_UR50D        Random Forest       0.813250      0.028932   \n",
      "3      esm2_t6_8M_UR50D              XGBoost       0.832648      0.025130   \n",
      "0   esm2_t33_650M_UR50D            SVM (RBF)       0.945498      0.025832   \n",
      "1   esm2_t33_650M_UR50D  Logistic Regression       0.953284      0.018898   \n",
      "2   esm2_t33_650M_UR50D        Random Forest       0.924120      0.009548   \n",
      "3   esm2_t33_650M_UR50D              XGBoost       0.920198      0.020896   \n",
      "0     esm2_t36_3B_UR50D            SVM (RBF)       0.953246      0.029863   \n",
      "1     esm2_t36_3B_UR50D  Logistic Regression       0.951380      0.021237   \n",
      "2     esm2_t36_3B_UR50D        Random Forest       0.951304      0.024743   \n",
      "3     esm2_t36_3B_UR50D              XGBoost       0.957186      0.019055   \n",
      "\n",
      "   AUC_mean   AUC_std  Precision (Type A)  Recall (Type A)  F1-Score (Type A)  \\\n",
      "0  0.975086  0.016736            0.956779         0.953051           0.953919   \n",
      "1  0.967749  0.009337            0.960000         0.963164           0.961217   \n",
      "2  0.975020  0.010086            0.927071         0.953107           0.938686   \n",
      "3  0.970990  0.011822            0.949281         0.936328           0.942139   \n",
      "0  0.946324  0.024101            0.876729         0.909492           0.891952   \n",
      "1  0.949524  0.024467            0.925674         0.939661           0.931825   \n",
      "2  0.891817  0.035548            0.795625         0.912938           0.850022   \n",
      "3  0.905122  0.028464            0.833853         0.889435           0.859431   \n",
      "0  0.980221  0.012041            0.949882         0.956497           0.952812   \n",
      "1  0.977789  0.015524            0.950986         0.969831           0.959961   \n",
      "2  0.972160  0.008655            0.920269         0.953107           0.935804   \n",
      "3  0.968133  0.011066            0.916986         0.949887           0.932137   \n",
      "0  0.978278  0.012166            0.969252         0.949718           0.958652   \n",
      "1  0.972198  0.014918            0.954865         0.963220           0.958227   \n",
      "2  0.977865  0.012525            0.953491         0.963107           0.957853   \n",
      "3  0.973826  0.013527            0.959966         0.966497           0.963018   \n",
      "\n",
      "   Precision (Type B)  Recall (Type B)  F1-Score (Type B)  \n",
      "0            0.940395         0.939958           0.938555  \n",
      "1            0.951102         0.944503           0.947138  \n",
      "2            0.936919         0.893975           0.912337  \n",
      "3            0.916581         0.930655           0.922548  \n",
      "0            0.875256         0.824207           0.846967  \n",
      "1            0.916634         0.893975           0.903552  \n",
      "2            0.850355         0.676004           0.752439  \n",
      "3            0.840824         0.754863           0.792249  \n",
      "0            0.941641         0.930550           0.935425  \n",
      "1            0.958743         0.930761           0.943878  \n",
      "2            0.933528         0.884567           0.907083  \n",
      "3            0.931314         0.879598           0.902793  \n",
      "0            0.936365         0.958351           0.946102  \n",
      "1            0.951212         0.935624           0.941682  \n",
      "2            0.950985         0.935201           0.942273  \n",
      "3            0.954618         0.944503           0.949147  \n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "#  ESM Benchmark\n",
    "\n",
    "import torch, esm, pandas as pd, numpy as np, time, os, warnings\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\\n\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "dataset = pd.read_excel(\"KRc.xlsx\", usecols=[\"sequence\", \"label\"])\n",
    "sequences = dataset[\"sequence\"].astype(str).tolist()\n",
    "labels = dataset[\"label\"].to_numpy()\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "def get_embeddings(model_name, save_name, batch_size=8):\n",
    "    print(f\"\\n[{model_name}] Loading model...\")\n",
    "    model, alphabet = getattr(esm.pretrained, model_name)()\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    model.eval().to(device)\n",
    "    num_layers = model.num_layers\n",
    "    print(f\"Model loaded âœ“  ({sum(p.numel() for p in model.parameters())/1e6:.1f} M params)\")\n",
    "\n",
    "    if os.path.exists(save_name):\n",
    "        print(f\"ðŸ”¹ Found cached file: {save_name}\")\n",
    "        return pd.read_csv(save_name)\n",
    "\n",
    "    all_embs = []\n",
    "    print(f\"Generating embeddings ({len(sequences)} sequences)...\")\n",
    "    for i in tqdm(range(0, len(sequences), batch_size)):\n",
    "        batch = [(f\"seq_{j}\", seq) for j, seq in enumerate(sequences[i:i+batch_size])]\n",
    "        _, _, batch_tokens = batch_converter(batch)\n",
    "        batch_tokens = batch_tokens.to(device)\n",
    "        with torch.no_grad():\n",
    "            results = model(batch_tokens, repr_layers=[num_layers], return_contacts=False)\n",
    "        reps = results[\"representations\"][num_layers]\n",
    "        seq_reps = [\n",
    "            reps[k, 1:(batch_tokens[k] != alphabet.padding_idx).sum()-1].mean(0).cpu().numpy()\n",
    "            for k in range(len(batch))\n",
    "        ]\n",
    "        all_embs.extend(seq_reps)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    df = pd.DataFrame(np.array(all_embs))\n",
    "    df.to_csv(save_name, index=False)\n",
    "    print(f\"âœ… Saved â†’ {save_name}\\n\")\n",
    "    return df\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "model_list = {\n",
    "    \"esm1b_t33_650M_UR50S\": \"ESM1b_650M.csv\",\n",
    "    \"esm2_t6_8M_UR50D\":     \"ESM2_8M.csv\",\n",
    "    \"esm2_t33_650M_UR50D\":  \"ESM2_650M.csv\",\n",
    "    \"esm2_t36_3B_UR50D\":    \"ESM2_3B.csv\",\n",
    "}\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "def evaluate_classifiers_cv(X, y, n_splits=5):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    classifiers = {\n",
    "        \"SVM (RBF)\": SVC(kernel=\"rbf\", probability=True, random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=2000, random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(\n",
    "            n_estimators=300, class_weight=\"balanced\", random_state=42\n",
    "        ),\n",
    "        \"XGBoost\": XGBClassifier(\n",
    "            use_label_encoder=False, eval_metric=\"logloss\", random_state=42\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    for name, clf in classifiers.items():\n",
    "        acc_scores, auc_scores = [], []\n",
    "        pA, rA, fA, pB, rB, fB = [], [], [], [], [], []\n",
    "        print(f\"\\nðŸ”¹ {name} ({n_splits}-fold CV)\")\n",
    "\n",
    "        for fold, (train_idx, test_idx) in enumerate(cv.split(X_scaled, y), 1):\n",
    "            X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            y_prob = (\n",
    "                clf.predict_proba(X_test)[:, 1]\n",
    "                if hasattr(clf, \"predict_proba\")\n",
    "                else y_pred\n",
    "            )\n",
    "\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_prob)\n",
    "            report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "            acc_scores.append(acc)\n",
    "            auc_scores.append(auc)\n",
    "            pA.append(report[\"1\"][\"precision\"])\n",
    "            rA.append(report[\"1\"][\"recall\"])\n",
    "            fA.append(report[\"1\"][\"f1-score\"])\n",
    "            pB.append(report[\"0\"][\"precision\"])\n",
    "            rB.append(report[\"0\"][\"recall\"])\n",
    "            fB.append(report[\"0\"][\"f1-score\"])\n",
    "\n",
    "            print(f\"  Fold {fold}: acc={acc:.4f}, auc={auc:.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Classifier\": name,\n",
    "            \"Accuracy_mean\": np.mean(acc_scores),\n",
    "            \"Accuracy_std\": np.std(acc_scores),\n",
    "            \"AUC_mean\": np.mean(auc_scores),\n",
    "            \"AUC_std\": np.std(auc_scores),\n",
    "            \"Precision (Type A)\": np.mean(pA),\n",
    "            \"Recall (Type A)\": np.mean(rA),\n",
    "            \"F1-Score (Type A)\": np.mean(fA),\n",
    "            \"Precision (Type B)\": np.mean(pB),\n",
    "            \"Recall (Type B)\": np.mean(rB),\n",
    "            \"F1-Score (Type B)\": np.mean(fB),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "excel_path = \"ESM_Benchmark_5fold.xlsx\"\n",
    "summary = []\n",
    "\n",
    "with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "    for model_name, file_name in model_list.items():\n",
    "        print(f\"\\n=== Evaluating {model_name} ===\")\n",
    "        t0 = time.time()\n",
    "\n",
    "        df = get_embeddings(model_name, file_name)\n",
    "        X = df.to_numpy()\n",
    "\n",
    "        res = evaluate_classifiers_cv(X, labels, n_splits=5)\n",
    "        res[\"Model\"] = model_name\n",
    "        summary.append(res)\n",
    "\n",
    "        sheet = model_name.replace(\"esm\", \"\").replace(\"_UR50D\",\"\").replace(\"_UR50S\",\"\")[:31]\n",
    "        res.to_excel(writer, sheet_name=sheet, index=False)\n",
    "\n",
    "        print(f\"â±  {model_name} done in {(time.time()-t0)/60:.1f} min\\n\")\n",
    "\n",
    "    summary_df = pd.concat(summary)\n",
    "    summary_df = summary_df[\n",
    "        [\n",
    "            \"Model\", \"Classifier\",\n",
    "            \"Accuracy_mean\", \"Accuracy_std\",\n",
    "            \"AUC_mean\", \"AUC_std\",\n",
    "            \"Precision (Type A)\", \"Recall (Type A)\", \"F1-Score (Type A)\",\n",
    "            \"Precision (Type B)\", \"Recall (Type B)\", \"F1-Score (Type B)\"\n",
    "        ]\n",
    "    ]\n",
    "    summary_df.to_excel(writer, sheet_name=\"Summary_All\", index=False)\n",
    "\n",
    "print(f\"\\nâœ… All results saved to {excel_path}\\n\")\n",
    "print(\"ðŸ Final Summary\")\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUpbNoJgsxY3"
   },
   "outputs": [],
   "source": [
    "#non_strep_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet A columns: ['aetokthonostatin', 'aesB', 'M6', 'A1KR', 'Aetokthonos hydrillicola Thurmond2011', 'Cyanobacteriota', 'GVYLIFGGLGRVGLLLALDLAQRVKAKLVLVSRSELPPRYKIRNLIDIEKAGGEVMTIAADVTDLDQMRSLR-RIQ--GQIHGVFHAAAITS-NRFLKEVGIEESTVQFAPKVFGLYLLEEVFGQ--PDFFVLLSSNASILGGLGFCAYSAANHFLDYFAADRNHQAVPWISTNWDRWLLE-HE---EAYT--TSMDAFAMTPQQSLEAMRRIITQ--EQVVVTPGNLQDRLKIWIQ----QSKQNN']\n",
      "Sheet B columns: ['BGC0000102.1 ', 'mycAI', 'M1', 'B1KR', 'Micromonospora griseorubida', 'Actinomycetes', 'GTVLVTGGTGALGARVARWLADHGAEHLVLVSRRGAQATGAAELVAGLERTGVRVTVAACDVADRDGAGRPAGGAPAGRPDGGPAHSRGSGC---------------GVPAERLAATHLHDLTAHR-LDAFVLFSSIVGSWGNAGQAAYAAANAALDALAEQRRSAGLPATSIAWGLWAGG-MAD---GEQTFTRRGVRAMDPDDGIAALRQALDS--TCVTVADVDWPSMVRTHANPAAARLFEEI']\n",
      "Detected sequence column in A: GVYLIFGGLGRVGLLLALDLAQRVKAKLVLVSRSELPPRYKIRNLIDIEKAGGEVMTIAADVTDLDQMRSLR-RIQ--GQIHGVFHAAAITS-NRFLKEVGIEESTVQFAPKVFGLYLLEEVFGQ--PDFFVLLSSNASILGGLGFCAYSAANHFLDYFAADRNHQAVPWISTNWDRWLLE-HE---EAYT--TSMDAFAMTPQQSLEAMRRIITQ--EQVVVTPGNLQDRLKIWIQ----QSKQNN\n",
      "Detected sequence column in B: GTVLVTGGTGALGARVARWLADHGAEHLVLVSRRGAQATGAAELVAGLERTGVRVTVAACDVADRDGAGRPAGGAPAGRPDGGPAHSRGSGC---------------GVPAERLAATHLHDLTAHR-LDAFVLFSSIVGSWGNAGQAAYAAANAALDALAEQRRSAGLPATSIAWGLWAGG-MAD---GEQTFTRRGVRAMDPDDGIAALRQALDS--TCVTVADVDWPSMVRTHANPAAARLFEEI\n",
      "âœ… Loaded 201 total sequences after cleaning\n",
      "   label                                     sequence_clean\n",
      "0      1  GTVLITGGTGGVAAHVARRLAALGADHLVLTSRRGPSAPGAPALAA...\n",
      "1      1  GTVLITGGTGALGSRVARSLARDGAEHLVLTSRRGPAAAGAAGLRA...\n",
      "2      1  GTILVTGGTAGLGAEVARWLAGRGAEHLALVSRRGPDTEGVGDLTA...\n",
      "3      1  GTVLVTGGTGGIGAHVARWLARSGAEHLVLLGRRGADAPGASELRE...\n",
      "4      1  GTALVTGGTGALGGHVARHLARCGVEDLVLVSRRGVDAPGAAELEA...\n",
      "Saved â†’ KRc_nonStreptomyces_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "file_path = \"non_strep_sequences.xlsx\"\n",
    "df_A = pd.read_excel(file_path, sheet_name=\"A\")\n",
    "df_B = pd.read_excel(file_path, sheet_name=\"B\")\n",
    "\n",
    "print(\"Sheet A columns:\", list(df_A.columns))\n",
    "print(\"Sheet B columns:\", list(df_B.columns))\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "def detect_sequence_column(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].astype(str).str.match(r'^[A-Z\\-]{30,}$', na=False).sum() > len(df) * 0.5:\n",
    "            return col\n",
    "    return df.columns[-1]  # fallback\n",
    "\n",
    "seq_col_A = detect_sequence_column(df_A)\n",
    "seq_col_B = detect_sequence_column(df_B)\n",
    "\n",
    "print(f\"Detected sequence column in A: {seq_col_A}\")\n",
    "print(f\"Detected sequence column in B: {seq_col_B}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "def remove_gaps(seq):\n",
    "    if pd.isna(seq):\n",
    "        return None\n",
    "    return seq.replace(\"-\", \"\").replace(\" \", \"\").strip()\n",
    "\n",
    "df_A[\"sequence_clean\"] = df_A[seq_col_A].apply(remove_gaps)\n",
    "df_B[\"sequence_clean\"] = df_B[seq_col_B].apply(remove_gaps)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "df_A[\"label\"] = 1\n",
    "df_B[\"label\"] = 0\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "dataset = pd.concat([df_A, df_B], ignore_index=True)\n",
    "dataset = dataset.dropna(subset=[\"sequence_clean\"])  # drop blanks\n",
    "\n",
    "print(f\"âœ… Loaded {len(dataset)} total sequences after cleaning\")\n",
    "print(dataset[[\"label\", \"sequence_clean\"]].head())\n",
    "\n",
    "dataset.to_csv(\"KRc_nonStreptomyces_cleaned.csv\", index=False)\n",
    "print(\"Saved â†’ KRc_nonStreptomyces_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Total sequences: 201 | A-type: 114 | B-type: 87\n",
      "\n",
      "\n",
      "[esm2_t36_3B_UR50D] Loading model...\n",
      "Model loaded âœ“  (2839.0 M params)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:08<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved â†’ ESM2_3B_nonStreptomyces.csv\n",
      "\n",
      "\n",
      "ðŸ”¹ Running 5-fold CV for SVM (RBF) ...\n",
      "  Fold 1: Acc=0.9024, AUC=0.9469, Prec=0.9130, Rec=0.9130, F1=0.9130\n",
      "  Fold 2: Acc=1.0000, AUC=1.0000, Prec=1.0000, Rec=1.0000, F1=1.0000\n",
      "  Fold 3: Acc=0.9500, AUC=0.9974, Prec=1.0000, Rec=0.9130, F1=0.9545\n",
      "  Fold 4: Acc=0.9000, AUC=0.9770, Prec=0.9524, Rec=0.8696, F1=0.9091\n",
      "  Fold 5: Acc=0.9000, AUC=0.9848, Prec=0.9091, Rec=0.9091, F1=0.9091\n",
      "\n",
      "ðŸ”¹ Running 5-fold CV for Logistic Regression ...\n",
      "  Fold 1: Acc=0.9268, AUC=0.9396, Prec=0.9167, Rec=0.9565, F1=0.9362\n",
      "  Fold 2: Acc=0.9500, AUC=0.9949, Prec=0.9565, Rec=0.9565, F1=0.9565\n",
      "  Fold 3: Acc=0.9500, AUC=0.9565, Prec=0.9200, Rec=1.0000, F1=0.9583\n",
      "  Fold 4: Acc=0.9000, AUC=0.9668, Prec=0.9524, Rec=0.8696, F1=0.9091\n",
      "  Fold 5: Acc=0.9000, AUC=0.9848, Prec=0.9091, Rec=0.9091, F1=0.9091\n",
      "\n",
      "ðŸ”¹ Running 5-fold CV for Random Forest ...\n",
      "  Fold 1: Acc=0.9024, AUC=0.9191, Prec=0.9130, Rec=0.9130, F1=0.9130\n",
      "  Fold 2: Acc=1.0000, AUC=1.0000, Prec=1.0000, Rec=1.0000, F1=1.0000\n",
      "  Fold 3: Acc=0.9250, AUC=0.9949, Prec=0.9167, Rec=0.9565, F1=0.9362\n",
      "  Fold 4: Acc=0.8750, AUC=0.9463, Prec=0.9091, Rec=0.8696, F1=0.8889\n",
      "  Fold 5: Acc=0.9500, AUC=0.9899, Prec=0.9545, Rec=0.9545, F1=0.9545\n",
      "\n",
      "ðŸ”¹ Running 5-fold CV for XGBoost ...\n",
      "  Fold 1: Acc=0.9024, AUC=0.9444, Prec=0.9130, Rec=0.9130, F1=0.9130\n",
      "  Fold 2: Acc=0.9500, AUC=1.0000, Prec=0.9200, Rec=1.0000, F1=0.9583\n",
      "  Fold 3: Acc=0.9250, AUC=0.9770, Prec=0.8846, Rec=1.0000, F1=0.9388\n",
      "  Fold 4: Acc=0.8500, AUC=0.9437, Prec=0.8696, Rec=0.8696, F1=0.8696\n",
      "  Fold 5: Acc=0.8750, AUC=0.9470, Prec=0.9048, Rec=0.8636, F1=0.8837\n",
      "\n",
      "ðŸ Final 5-Fold CV Results\n",
      "            Classifier  Mean_Accuracy  Std_Accuracy  Mean_AUC   Std_AUC  \\\n",
      "0            SVM (RBF)       0.930488      0.039644  0.981227  0.019119   \n",
      "1  Logistic Regression       0.925366      0.022373  0.968524  0.019720   \n",
      "2        Random Forest       0.930488      0.042681  0.970032  0.031843   \n",
      "3              XGBoost       0.900488      0.035369  0.962426  0.022518   \n",
      "\n",
      "   Mean_Precision  Std_Precision  Mean_Recall  Std_Recall   Mean_F1    Std_F1  \n",
      "0        0.954903       0.039812     0.920949    0.042790  0.937154  0.035801  \n",
      "1        0.930932       0.019570     0.938340    0.044830  0.933841  0.021656  \n",
      "2        0.938669       0.034725     0.938735    0.044191  0.938530  0.037827  \n",
      "3        0.898397       0.018670     0.929249    0.060235  0.912688  0.033054  \n"
     ]
    }
   ],
   "source": [
    "import torch, esm, pandas as pd, numpy as np, time\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score,\n",
    "    recall_score, f1_score\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\\n\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "file_path = \"KRc_nonStreptomyces_cleaned.csv\"\n",
    "dataset = pd.read_csv(file_path)\n",
    "\n",
    "seq_col = \"sequence_clean\" if \"sequence_clean\" in dataset.columns else dataset.columns[-1]\n",
    "sequences = dataset[seq_col].astype(str).tolist()\n",
    "labels = dataset[\"label\"].to_numpy()\n",
    "\n",
    "print(f\"Total sequences: {len(sequences)} | A-type: {sum(labels)} | B-type: {len(labels)-sum(labels)}\\n\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "def get_embeddings(model_name=\"esm2_t36_3B_UR50D\", batch_size=4):\n",
    "    print(f\"\\n[{model_name}] Loading model...\")\n",
    "    model, alphabet = getattr(esm.pretrained, model_name)()\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    model.eval().to(device)\n",
    "    num_layers = model.num_layers\n",
    "    print(f\"Model loaded âœ“  ({sum(p.numel() for p in model.parameters())/1e6:.1f} M params)\\n\")\n",
    "\n",
    "    all_embs = []\n",
    "    for i in tqdm(range(0, len(sequences), batch_size)):\n",
    "        batch = [(f\"seq_{j}\", seq) for j, seq in enumerate(sequences[i:i+batch_size])]\n",
    "        _, _, batch_tokens = batch_converter(batch)\n",
    "        batch_tokens = batch_tokens.to(device)\n",
    "        with torch.no_grad():\n",
    "            results = model(batch_tokens, repr_layers=[num_layers], return_contacts=False)\n",
    "        reps = results[\"representations\"][num_layers]\n",
    "        seq_reps = [\n",
    "            reps[k, 1:(batch_tokens[k] != alphabet.padding_idx).sum()-1].mean(0).cpu().numpy()\n",
    "            for k in range(len(batch))\n",
    "        ]\n",
    "        all_embs.extend(seq_reps)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    emb_df = pd.DataFrame(np.array(all_embs))\n",
    "    emb_df.to_csv(\"ESM2_3B_nonStreptomyces.csv\", index=False)\n",
    "    print(\"Embeddings saved â†’ ESM2_3B_nonStreptomyces.csv\\n\")\n",
    "    return emb_df\n",
    "\n",
    "X = get_embeddings()\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "def cross_validate_classifiers(X, y, n_splits=5):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    classifiers = {\n",
    "        \"SVM (RBF)\": SVC(kernel=\"rbf\", probability=True, random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=2000, random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=300, class_weight=\"balanced\", random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for name, clf in classifiers.items():\n",
    "        acc_scores, auc_scores, prec_scores, rec_scores, f1_scores = [], [], [], [], []\n",
    "        print(f\"\\nðŸ”¹ Running {n_splits}-fold CV for {name} ...\")\n",
    "\n",
    "        for fold, (train_idx, test_idx) in enumerate(skf.split(X_scaled, y), 1):\n",
    "            X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            y_prob = clf.predict_proba(X_test)[:, 1] if hasattr(clf, \"predict_proba\") else y_pred\n",
    "\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_prob)\n",
    "            prec = precision_score(y_test, y_pred)\n",
    "            rec = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            acc_scores.append(acc)\n",
    "            auc_scores.append(auc)\n",
    "            prec_scores.append(prec)\n",
    "            rec_scores.append(rec)\n",
    "            f1_scores.append(f1)\n",
    "\n",
    "            print(f\"  Fold {fold}: Acc={acc:.4f}, AUC={auc:.4f}, Prec={prec:.4f}, Rec={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "        results.append((\n",
    "            name,\n",
    "            np.mean(acc_scores), np.std(acc_scores),\n",
    "            np.mean(auc_scores), np.std(auc_scores),\n",
    "            np.mean(prec_scores), np.std(prec_scores),\n",
    "            np.mean(rec_scores), np.std(rec_scores),\n",
    "            np.mean(f1_scores), np.std(f1_scores)\n",
    "        ))\n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=[\n",
    "        \"Classifier\",\n",
    "        \"Mean_Accuracy\", \"Std_Accuracy\",\n",
    "        \"Mean_AUC\", \"Std_AUC\",\n",
    "        \"Mean_Precision\", \"Std_Precision\",\n",
    "        \"Mean_Recall\", \"Std_Recall\",\n",
    "        \"Mean_F1\", \"Std_F1\"\n",
    "    ])\n",
    "    return results_df\n",
    "\n",
    "results_df = cross_validate_classifiers(X.to_numpy(), labels)\n",
    "results_df.to_csv(\"ESM2_3B_nonStreptomyces_5fold_fullmetrics.csv\", index=False)\n",
    "\n",
    "print(\"\\nðŸ Final 5-Fold CV Results\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
