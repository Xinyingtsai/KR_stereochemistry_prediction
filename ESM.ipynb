{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# ==========================================================\n",
    "#  ESM Benchmark\n",
    "\n",
    "import torch, esm, pandas as pd, numpy as np, time, os, warnings\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\\n\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "dataset = pd.read_excel(\"KRc.xlsx\", usecols=[\"sequence\", \"label\"])\n",
    "sequences = dataset[\"sequence\"].astype(str).tolist()\n",
    "labels = dataset[\"label\"].to_numpy()\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "def get_embeddings(model_name, save_name, batch_size=8):\n",
    "    print(f\"\\n[{model_name}] Loading model...\")\n",
    "    model, alphabet = getattr(esm.pretrained, model_name)()\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    model.eval().to(device)\n",
    "    num_layers = model.num_layers\n",
    "    print(f\"Model loaded ‚úì  ({sum(p.numel() for p in model.parameters())/1e6:.1f} M params)\")\n",
    "\n",
    "    if os.path.exists(save_name):\n",
    "        print(f\"üîπ Found cached file: {save_name}\")\n",
    "        return pd.read_csv(save_name)\n",
    "\n",
    "    all_embs = []\n",
    "    print(f\"Generating embeddings ({len(sequences)} sequences)...\")\n",
    "    for i in tqdm(range(0, len(sequences), batch_size)):\n",
    "        batch = [(f\"seq_{j}\", seq) for j, seq in enumerate(sequences[i:i+batch_size])]\n",
    "        _, _, batch_tokens = batch_converter(batch)\n",
    "        batch_tokens = batch_tokens.to(device)\n",
    "        with torch.no_grad():\n",
    "            results = model(batch_tokens, repr_layers=[num_layers], return_contacts=False)\n",
    "        reps = results[\"representations\"][num_layers]\n",
    "        seq_reps = [\n",
    "            reps[k, 1:(batch_tokens[k] != alphabet.padding_idx).sum()-1].mean(0).cpu().numpy()\n",
    "            for k in range(len(batch))\n",
    "        ]\n",
    "        all_embs.extend(seq_reps)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    df = pd.DataFrame(np.array(all_embs))\n",
    "    df.to_csv(save_name, index=False)\n",
    "    print(f\"‚úÖ Saved ‚Üí {save_name}\\n\")\n",
    "    return df\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "model_list = {\n",
    "    \"esm1b_t33_650M_UR50S\": \"ESM1b_650M.csv\",\n",
    "    \"esm2_t6_8M_UR50D\":     \"ESM2_8M.csv\",\n",
    "    \"esm2_t33_650M_UR50D\":  \"ESM2_650M.csv\",\n",
    "    \"esm2_t36_3B_UR50D\":    \"ESM2_3B.csv\",\n",
    "}\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "def evaluate_classifiers_cv(X, y, n_splits=5):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    classifiers = {\n",
    "        \"SVM (RBF)\": SVC(kernel=\"rbf\", probability=True, random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=2000, random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(\n",
    "            n_estimators=300, class_weight=\"balanced\", random_state=42\n",
    "        ),\n",
    "        \"XGBoost\": XGBClassifier(\n",
    "            use_label_encoder=False, eval_metric=\"logloss\", random_state=42\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    for name, clf in classifiers.items():\n",
    "        acc_scores, auc_scores = [], []\n",
    "        pA, rA, fA, pB, rB, fB = [], [], [], [], [], []\n",
    "        print(f\"\\nüîπ {name} ({n_splits}-fold CV)\")\n",
    "\n",
    "        for fold, (train_idx, test_idx) in enumerate(cv.split(X_scaled, y), 1):\n",
    "            X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            y_prob = (\n",
    "                clf.predict_proba(X_test)[:, 1]\n",
    "                if hasattr(clf, \"predict_proba\")\n",
    "                else y_pred\n",
    "            )\n",
    "\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_prob)\n",
    "            report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "            acc_scores.append(acc)\n",
    "            auc_scores.append(auc)\n",
    "            pA.append(report[\"1\"][\"precision\"])\n",
    "            rA.append(report[\"1\"][\"recall\"])\n",
    "            fA.append(report[\"1\"][\"f1-score\"])\n",
    "            pB.append(report[\"0\"][\"precision\"])\n",
    "            rB.append(report[\"0\"][\"recall\"])\n",
    "            fB.append(report[\"0\"][\"f1-score\"])\n",
    "\n",
    "            print(f\"  Fold {fold}: acc={acc:.4f}, auc={auc:.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Classifier\": name,\n",
    "            \"Accuracy_mean\": np.mean(acc_scores),\n",
    "            \"Accuracy_std\": np.std(acc_scores),\n",
    "            \"AUC_mean\": np.mean(auc_scores),\n",
    "            \"AUC_std\": np.std(auc_scores),\n",
    "            \"Precision (Type A)\": np.mean(pA),\n",
    "            \"Recall (Type A)\": np.mean(rA),\n",
    "            \"F1-Score (Type A)\": np.mean(fA),\n",
    "            \"Precision (Type B)\": np.mean(pB),\n",
    "            \"Recall (Type B)\": np.mean(rB),\n",
    "            \"F1-Score (Type B)\": np.mean(fB),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "excel_path = \"ESM_Benchmark_5fold.xlsx\"\n",
    "summary = []\n",
    "\n",
    "with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "    for model_name, file_name in model_list.items():\n",
    "        print(f\"\\n=== Evaluating {model_name} ===\")\n",
    "        t0 = time.time()\n",
    "\n",
    "        df = get_embeddings(model_name, file_name)\n",
    "        X = df.to_numpy()\n",
    "\n",
    "        res = evaluate_classifiers_cv(X, labels, n_splits=5)\n",
    "        res[\"Model\"] = model_name\n",
    "        summary.append(res)\n",
    "\n",
    "        sheet = model_name.replace(\"esm\", \"\").replace(\"_UR50D\",\"\").replace(\"_UR50S\",\"\")[:31]\n",
    "        res.to_excel(writer, sheet_name=sheet, index=False)\n",
    "\n",
    "        print(f\"‚è±  {model_name} done in {(time.time()-t0)/60:.1f} min\\n\")\n",
    "\n",
    "    summary_df = pd.concat(summary)\n",
    "    summary_df = summary_df[\n",
    "        [\n",
    "            \"Model\", \"Classifier\",\n",
    "            \"Accuracy_mean\", \"Accuracy_std\",\n",
    "            \"AUC_mean\", \"AUC_std\",\n",
    "            \"Precision (Type A)\", \"Recall (Type A)\", \"F1-Score (Type A)\",\n",
    "            \"Precision (Type B)\", \"Recall (Type B)\", \"F1-Score (Type B)\"\n",
    "        ]\n",
    "    ]\n",
    "    summary_df.to_excel(writer, sheet_name=\"Summary_All\", index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ All results saved to {excel_path}\\n\")\n",
    "print(\"üèÅ Final Summary\")\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUpbNoJgsxY3"
   },
   "outputs": [],
   "source": [
    "#non_strep_sequences"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "file_path = \"non_strep_sequences.xlsx\"\n",
    "df_A = pd.read_excel(file_path, sheet_name=\"A\")\n",
    "df_B = pd.read_excel(file_path, sheet_name=\"B\")\n",
    "\n",
    "print(\"Sheet A columns:\", list(df_A.columns))\n",
    "print(\"Sheet B columns:\", list(df_B.columns))\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "def detect_sequence_column(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].astype(str).str.match(r'^[A-Z\\-]{30,}$', na=False).sum() > len(df) * 0.5:\n",
    "            return col\n",
    "    return df.columns[-1]  # fallback\n",
    "\n",
    "seq_col_A = detect_sequence_column(df_A)\n",
    "seq_col_B = detect_sequence_column(df_B)\n",
    "\n",
    "print(f\"Detected sequence column in A: {seq_col_A}\")\n",
    "print(f\"Detected sequence column in B: {seq_col_B}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "def remove_gaps(seq):\n",
    "    if pd.isna(seq):\n",
    "        return None\n",
    "    return seq.replace(\"-\", \"\").replace(\" \", \"\").strip()\n",
    "\n",
    "df_A[\"sequence_clean\"] = df_A[seq_col_A].apply(remove_gaps)\n",
    "df_B[\"sequence_clean\"] = df_B[seq_col_B].apply(remove_gaps)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "df_A[\"label\"] = 1\n",
    "df_B[\"label\"] = 0\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "dataset = pd.concat([df_A, df_B], ignore_index=True)\n",
    "dataset = dataset.dropna(subset=[\"sequence_clean\"])  # drop blanks\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(dataset)} total sequences after cleaning\")\n",
    "print(dataset[[\"label\", \"sequence_clean\"]].head())\n",
    "\n",
    "dataset.to_csv(\"KRc_nonStreptomyces_cleaned.csv\", index=False)\n",
    "print(\"Saved ‚Üí KRc_nonStreptomyces_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import torch, esm, pandas as pd, numpy as np, time\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score,\n",
    "    recall_score, f1_score\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\\n\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "file_path = \"KRc_nonStreptomyces_cleaned.csv\"\n",
    "dataset = pd.read_csv(file_path)\n",
    "\n",
    "seq_col = \"sequence_clean\" if \"sequence_clean\" in dataset.columns else dataset.columns[-1]\n",
    "sequences = dataset[seq_col].astype(str).tolist()\n",
    "labels = dataset[\"label\"].to_numpy()\n",
    "\n",
    "print(f\"Total sequences: {len(sequences)} | A-type: {sum(labels)} | B-type: {len(labels)-sum(labels)}\\n\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "def get_embeddings(model_name=\"esm2_t36_3B_UR50D\", batch_size=4):\n",
    "    print(f\"\\n[{model_name}] Loading model...\")\n",
    "    model, alphabet = getattr(esm.pretrained, model_name)()\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    model.eval().to(device)\n",
    "    num_layers = model.num_layers\n",
    "    print(f\"Model loaded ‚úì  ({sum(p.numel() for p in model.parameters())/1e6:.1f} M params)\\n\")\n",
    "\n",
    "    all_embs = []\n",
    "    for i in tqdm(range(0, len(sequences), batch_size)):\n",
    "        batch = [(f\"seq_{j}\", seq) for j, seq in enumerate(sequences[i:i+batch_size])]\n",
    "        _, _, batch_tokens = batch_converter(batch)\n",
    "        batch_tokens = batch_tokens.to(device)\n",
    "        with torch.no_grad():\n",
    "            results = model(batch_tokens, repr_layers=[num_layers], return_contacts=False)\n",
    "        reps = results[\"representations\"][num_layers]\n",
    "        seq_reps = [\n",
    "            reps[k, 1:(batch_tokens[k] != alphabet.padding_idx).sum()-1].mean(0).cpu().numpy()\n",
    "            for k in range(len(batch))\n",
    "        ]\n",
    "        all_embs.extend(seq_reps)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    emb_df = pd.DataFrame(np.array(all_embs))\n",
    "    emb_df.to_csv(\"ESM2_3B_nonStreptomyces.csv\", index=False)\n",
    "    print(\"Embeddings saved ‚Üí ESM2_3B_nonStreptomyces.csv\\n\")\n",
    "    return emb_df\n",
    "\n",
    "X = get_embeddings()\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "def cross_validate_classifiers(X, y, n_splits=5):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    classifiers = {\n",
    "        \"SVM (RBF)\": SVC(kernel=\"rbf\", probability=True, random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=2000, random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=300, class_weight=\"balanced\", random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for name, clf in classifiers.items():\n",
    "        acc_scores, auc_scores, prec_scores, rec_scores, f1_scores = [], [], [], [], []\n",
    "        print(f\"\\nüîπ Running {n_splits}-fold CV for {name} ...\")\n",
    "\n",
    "        for fold, (train_idx, test_idx) in enumerate(skf.split(X_scaled, y), 1):\n",
    "            X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            y_prob = clf.predict_proba(X_test)[:, 1] if hasattr(clf, \"predict_proba\") else y_pred\n",
    "\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_prob)\n",
    "            prec = precision_score(y_test, y_pred)\n",
    "            rec = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            acc_scores.append(acc)\n",
    "            auc_scores.append(auc)\n",
    "            prec_scores.append(prec)\n",
    "            rec_scores.append(rec)\n",
    "            f1_scores.append(f1)\n",
    "\n",
    "            print(f\"  Fold {fold}: Acc={acc:.4f}, AUC={auc:.4f}, Prec={prec:.4f}, Rec={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "        results.append((\n",
    "            name,\n",
    "            np.mean(acc_scores), np.std(acc_scores),\n",
    "            np.mean(auc_scores), np.std(auc_scores),\n",
    "            np.mean(prec_scores), np.std(prec_scores),\n",
    "            np.mean(rec_scores), np.std(rec_scores),\n",
    "            np.mean(f1_scores), np.std(f1_scores)\n",
    "        ))\n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=[\n",
    "        \"Classifier\",\n",
    "        \"Mean_Accuracy\", \"Std_Accuracy\",\n",
    "        \"Mean_AUC\", \"Std_AUC\",\n",
    "        \"Mean_Precision\", \"Std_Precision\",\n",
    "        \"Mean_Recall\", \"Std_Recall\",\n",
    "        \"Mean_F1\", \"Std_F1\"\n",
    "    ])\n",
    "    return results_df\n",
    "\n",
    "results_df = cross_validate_classifiers(X.to_numpy(), labels)\n",
    "results_df.to_csv(\"ESM2_3B_nonStreptomyces_5fold_fullmetrics.csv\", index=False)\n",
    "\n",
    "print(\"\\nüèÅ Final 5-Fold CV Results\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
