{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8efbab92-9846-49a2-8b0f-40e8b36bef93",
   "metadata": {},
   "source": [
    "**Position file_141_123_91**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "81a5703a-5472-4b13-9346-f341c5a1b436",
   "metadata": {},
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "# Define input FASTA files\n",
    "fasta_type_A = \"typeA_aligned.fasta\"  \n",
    "fasta_type_B = \"typeB_aligned.fasta\"  \n",
    "\n",
    "# Define output CSV file\n",
    "output_csv = \"selected_kl_divergence_positions_141_123_91.csv\"\n",
    "\n",
    "# Define selected positions \n",
    "selected_positions = [141 - 1, 123 - 1, 91 - 1]\n",
    "\n",
    "# Function to extract residues at selected positions\n",
    "def extract_features(fasta_file, label):\n",
    "    data = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        seq_id = record.id\n",
    "        sequence = str(record.seq)\n",
    "        \n",
    "        # Extract residues at selected positions\n",
    "        residues = [sequence[pos] for pos in selected_positions]\n",
    "        \n",
    "        # Append data (ID, Residues, Label)\n",
    "        data.append([seq_id] + residues + [label])\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Process both Type A and Type B sequences\n",
    "data_A = extract_features(fasta_type_A, label=1)  # Type A = 1\n",
    "data_B = extract_features(fasta_type_B, label=0)  # Type B = 0\n",
    "\n",
    "# Combine both datasets\n",
    "all_data = data_A + data_B\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [\"ID\"] + [f\"pos_{pos+1}\" for pos in selected_positions] + [\"label\"]\n",
    "df = pd.DataFrame(all_data, columns=columns)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"CSV file saved as: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2745fabb-9e6f-405e-80e9-6840b6a82ded",
   "metadata": {},
   "source": [
    "**Position file_141**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd537f69-2d3f-4399-ba7c-12d6cd654cb8",
   "metadata": {},
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "# Define input FASTA files\n",
    "fasta_type_A = \"typeA_aligned.fasta\"  \n",
    "fasta_type_B = \"typeB_aligned.fasta\"  \n",
    "\n",
    "# Define output CSV file\n",
    "output_csv = \"selected_kl_divergence_positions_141.csv\"\n",
    "\n",
    "# Define selected positions \n",
    "selected_positions = [141 - 1]\n",
    "\n",
    "# Function to extract residues at selected positions\n",
    "def extract_features(fasta_file, label):\n",
    "    data = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        seq_id = record.id\n",
    "        sequence = str(record.seq)\n",
    "        \n",
    "        # Extract residues at selected positions\n",
    "        residues = [sequence[pos] for pos in selected_positions]\n",
    "        \n",
    "        # Append data (ID, Residues, Label)\n",
    "        data.append([seq_id] + residues + [label])\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Process both Type A and Type B sequences\n",
    "data_A = extract_features(fasta_type_A, label=1)  # Type A = 1\n",
    "data_B = extract_features(fasta_type_B, label=0)  # Type B = 0\n",
    "\n",
    "# Combine both datasets\n",
    "all_data = data_A + data_B\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [\"ID\"] + [f\"pos_{pos+1}\" for pos in selected_positions] + [\"label\"]\n",
    "df = pd.DataFrame(all_data, columns=columns)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"CSV file saved as: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30ac92c-f922-4faa-bb6c-905d3f1b8b72",
   "metadata": {},
   "source": [
    "**Position file_137_192_196**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1655ee18-7639-41ca-a040-d5d73e3d4084",
   "metadata": {},
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "# Define input FASTA files\n",
    "fasta_type_A = \"typeA_aligned.fasta\"  \n",
    "fasta_type_B = \"typeB_aligned.fasta\"  \n",
    "\n",
    "# Define output CSV file\n",
    "output_csv = \"selected_kl_divergence_positions_192_196_137.csv\"\n",
    "\n",
    "# Define selected positions \n",
    "selected_positions = [192 - 1, 196 - 1, 137 - 1]\n",
    "\n",
    "# Function to extract residues at selected positions\n",
    "def extract_features(fasta_file, label):\n",
    "    data = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        seq_id = record.id\n",
    "        sequence = str(record.seq)\n",
    "        \n",
    "        # Extract residues at selected positions\n",
    "        residues = [sequence[pos] for pos in selected_positions]\n",
    "        \n",
    "        # Append data (ID, Residues, Label)\n",
    "        data.append([seq_id] + residues + [label])\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Process both Type A and Type B sequences\n",
    "data_A = extract_features(fasta_type_A, label=1)  # Type A = 1\n",
    "data_B = extract_features(fasta_type_B, label=0)  # Type B = 0\n",
    "\n",
    "# Combine both datasets\n",
    "all_data = data_A + data_B\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [\"ID\"] + [f\"pos_{pos+1}\" for pos in selected_positions] + [\"label\"]\n",
    "df = pd.DataFrame(all_data, columns=columns)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"CSV file saved as: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48ff1f8-adbb-4f5d-9ad5-c3f67fb84f85",
   "metadata": {},
   "source": [
    "**Position file_137**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b068da8f-3fc4-4723-ba09-e6017608ab36",
   "metadata": {},
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "# Define input FASTA files\n",
    "fasta_type_A = \"typeA_aligned.fasta\"  \n",
    "fasta_type_B = \"typeB_aligned.fasta\"  \n",
    "\n",
    "# Define output CSV file\n",
    "output_csv = \"selected_kl_divergence_positions_137.csv\"\n",
    "\n",
    "# Define selected positions (0-based index in Python, so subtract 1)\n",
    "selected_positions = [137 - 1]\n",
    "\n",
    "# Function to extract residues at selected positions\n",
    "def extract_features(fasta_file, label):\n",
    "    data = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        seq_id = record.id\n",
    "        sequence = str(record.seq)\n",
    "        \n",
    "        # Extract residues at selected positions\n",
    "        residues = [sequence[pos] for pos in selected_positions]\n",
    "        \n",
    "        # Append data (ID, Residues, Label)\n",
    "        data.append([seq_id] + residues + [label])\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Process both Type A and Type B sequences\n",
    "data_A = extract_features(fasta_type_A, label=1)  # Type A = 1\n",
    "data_B = extract_features(fasta_type_B, label=0)  # Type B = 0\n",
    "\n",
    "# Combine both datasets\n",
    "all_data = data_A + data_B\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [\"ID\"] + [f\"pos_{pos+1}\" for pos in selected_positions] + [\"label\"]\n",
    "df = pd.DataFrame(all_data, columns=columns)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"CSV file saved as: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1985fc4-7d65-4d43-b6e9-a7a8d293387e",
   "metadata": {},
   "source": [
    "**Classifier Model**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0604165-cf76-4042-a97e-03893c85d7bc",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv(\"selected_kl_divergence_positions_192_196_143.csv\")\n",
    "\n",
    "# Extract features and labels\n",
    "selected_positions = [col for col in df.columns if col.startswith(\"pos_\")]\n",
    "X = df[selected_positions].astype(str)\n",
    "y = df[\"label\"]\n",
    "\n",
    "# One-hot encoding\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "joblib.dump(encoder, \"one_hot_encoder.pkl\")\n",
    "\n",
    "# Define classifiers\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Support Vector Machine\": SVC(kernel=\"linear\", probability=True),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "}\n",
    "\n",
    "# Stratified 5-Fold Cross Validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "confusion_matrices = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    fold_acc = []\n",
    "    fold_auc = []\n",
    "    typeA_metrics = []\n",
    "    typeB_metrics = []\n",
    "\n",
    "    print(f\"\\nðŸ§© Training {model_name} with 5-fold cross-validation...\")\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X_encoded, y), 1):\n",
    "        X_train, X_test = X_encoded[train_idx], X_encoded[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_prob)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        fold_acc.append(acc)\n",
    "        fold_auc.append(auc)\n",
    "\n",
    "        # Store per-class metrics\n",
    "        typeA_metrics.append(report[\"1\"])\n",
    "        typeB_metrics.append(report[\"0\"])\n",
    "\n",
    "        # Save confusion matrix\n",
    "        confusion_matrices.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Fold\": fold,\n",
    "            \"Actual Type B - Predicted Type B\": conf_matrix[0, 0],\n",
    "            \"Actual Type B - Predicted Type A\": conf_matrix[0, 1],\n",
    "            \"Actual Type A - Predicted Type B\": conf_matrix[1, 0],\n",
    "            \"Actual Type A - Predicted Type A\": conf_matrix[1, 1]\n",
    "        })\n",
    "\n",
    "    # Average across folds\n",
    "    avg_typeA = pd.DataFrame(typeA_metrics).mean()\n",
    "    avg_typeB = pd.DataFrame(typeB_metrics).mean()\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Mean Accuracy\": np.mean(fold_acc),\n",
    "        \"Mean AUC\": np.mean(fold_auc),\n",
    "        \"Precision (Type A)\": avg_typeA[\"precision\"],\n",
    "        \"Recall (Type A)\": avg_typeA[\"recall\"],\n",
    "        \"F1-Score (Type A)\": avg_typeA[\"f1-score\"],\n",
    "        \"Precision (Type B)\": avg_typeB[\"precision\"],\n",
    "        \"Recall (Type B)\": avg_typeB[\"recall\"],\n",
    "        \"F1-Score (Type B)\": avg_typeB[\"f1-score\"]\n",
    "    })\n",
    "\n",
    "    # Save trained model from last fold\n",
    "    model_filename = f\"{model_name.replace(' ', '_').lower()}_cv_classifier.pkl\"\n",
    "    joblib.dump(model, model_filename)\n",
    "\n",
    "# Save results\n",
    "pd.DataFrame(results).to_csv(\"classification_results_5fold.csv\", index=False)\n",
    "pd.DataFrame(confusion_matrices).to_csv(\"confusion_matrices_5fold.csv\", index=False)\n",
    "\n",
    "print(\"\\nâœ… 5-fold CV results saved to 'classification_results_5fold.csv'\")\n",
    "print(\"âœ… Confusion matrices saved to 'confusion_matrices_5fold.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd8d79e-4e2d-41ae-8d66-202babfeccb5",
   "metadata": {},
   "source": [
    "**visualization of one-hot encoding**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8f9aa91-8c66-4dc9-b7b6-398118db77ee",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import umap\n",
    "\n",
    "def run_umap_and_plot(file, label_col=\"label\", color_a=\"#f5910c\", color_b=\"blue\",\n",
    "                      global_xlim=None, global_ylim=None, save_name=None):\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Extract selected positions\n",
    "    selected_positions = [col for col in df.columns if col.startswith(\"pos_\")]\n",
    "    X = df[selected_positions].astype(str)\n",
    "    y = df[label_col]  # A-type KR (1), B-type KR (0)\n",
    "\n",
    "    # One-hot encoding\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "    X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "    # --- UMAP ---\n",
    "    reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "    X_umap = reducer.fit_transform(X_encoded)\n",
    "\n",
    "    # --- Plot ---\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(X_umap[y == 1, 0], X_umap[y == 1, 1],\n",
    "                color=color_a, label=\"A-type KR\", alpha=0.8, s=10)\n",
    "    plt.scatter(X_umap[y == 0, 0], X_umap[y == 0, 1],\n",
    "                color=color_b, label=\"B-type KR\", alpha=0.8, s=10)\n",
    "\n",
    "    plt.xlabel(\"UMAP Component 1\")\n",
    "    plt.ylabel(\"UMAP Component 2\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    # Equal aspect ratio and unified scale\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "    # Use global limits if provided, otherwise compute from data\n",
    "    if global_xlim is not None and global_ylim is not None:\n",
    "        plt.xlim(global_xlim)\n",
    "        plt.ylim(global_ylim)\n",
    "        plt.xticks(np.arange(global_xlim[0], global_xlim[1] + 1, 1))\n",
    "        plt.yticks(np.arange(global_ylim[0], global_ylim[1] + 1, 1))\n",
    "    else:\n",
    "        x_min, x_max = np.floor(X_umap[:,0].min()), np.ceil(X_umap[:,0].max())\n",
    "        y_min, y_max = np.floor(X_umap[:,1].min()), np.ceil(X_umap[:,1].max())\n",
    "        plt.xlim(x_min, x_max)\n",
    "        plt.ylim(y_min, y_max)\n",
    "        plt.xticks(np.arange(x_min, x_max + 1, 1))\n",
    "        plt.yticks(np.arange(y_min, y_max + 1, 1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_name:\n",
    "        plt.savefig(save_name, dpi=1000)\n",
    "    plt.show()\n",
    "\n",
    "    return X_umap\n",
    "\n",
    "\n",
    "# --- Run both datasets ---\n",
    "file1 = \"selected_kl_divergence_positions_192_196_137.csv\"\n",
    "file2 = \"selected_kl_divergence_positions_141_123_91.csv\"\n",
    "\n",
    "# Compute embeddings first to find shared scale\n",
    "def get_bounds(X_umap):\n",
    "    return [np.floor(X_umap[:,0].min()), np.ceil(X_umap[:,0].max())], \\\n",
    "           [np.floor(X_umap[:,1].min()), np.ceil(X_umap[:,1].max())]\n",
    "\n",
    "# Run both first to compute bounds\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "enc = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "\n",
    "def encode_umap(df):\n",
    "    X = df[[col for col in df.columns if col.startswith(\"pos_\")]].astype(str)\n",
    "    y = df[\"label\"]\n",
    "    X_encoded = enc.fit_transform(X)\n",
    "    reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "    return reducer.fit_transform(X_encoded)\n",
    "\n",
    "umap1 = encode_umap(df1)\n",
    "umap2 = encode_umap(df2)\n",
    "\n",
    "xlim = [min(np.floor(umap1[:,0].min()), np.floor(umap2[:,0].min())),\n",
    "        max(np.ceil(umap1[:,0].max()), np.ceil(umap2[:,0].max()))]\n",
    "ylim = [min(np.floor(umap1[:,1].min()), np.floor(umap2[:,1].min())),\n",
    "        max(np.ceil(umap1[:,1].max()), np.ceil(umap2[:,1].max()))]\n",
    "\n",
    "# --- Final consistent plots ---\n",
    "run_umap_and_plot(file1, global_xlim=xlim, global_ylim=ylim, save_name=\"umap_192_196_137_equal.png\")\n",
    "run_umap_and_plot(file2, global_xlim=xlim, global_ylim=ylim, save_name=\"umap_141_123_91_equal.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (py37env)",
   "language": "python",
   "name": "py37env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
